{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d33d81",
   "metadata": {},
   "source": [
    "# 1D-CNN for ECG Arrhythmia Detection\n",
    "## Complete Medical-Grade Pipeline using MIT-BIH Arrhythmia Database\n",
    "\n",
    "This notebook implements a comprehensive deep learning solution for binary ECG arrhythmia classification following strict medical validation protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd9a89",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries\n",
    "\n",
    "Install and import all necessary libraries for data processing, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716218e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae09dc9",
   "metadata": {},
   "source": [
    "## Section 2: Load MIT-BIH Arrhythmia Dataset\n",
    "\n",
    "Load the training and test datasets from the Kaggle MIT-BIH ECG dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d20649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MIT-BIH Arrhythmia Database\n",
    "# Train and test datasets from Kaggle\n",
    "train_data = pd.read_csv('ecg_data/mitbih_train.csv', header=None)\n",
    "test_data = pd.read_csv('ecg_data/mitbih_test.csv', header=None)\n",
    "\n",
    "print(f\"âœ“ Training data loaded: Shape = {train_data.shape}\")\n",
    "print(f\"âœ“ Test data loaded: Shape = {test_data.shape}\")\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  - Total ECG samples: {train_data.shape[0] + test_data.shape[0]}\")\n",
    "print(f\"  - ECG signal length: {train_data.shape[1] - 1} time points\")\n",
    "print(f\"  - Last column contains class labels (0-4)\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nFirst 3 rows of training data:\")\n",
    "print(train_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e0fdf",
   "metadata": {},
   "source": [
    "## Section 3: Binary Label Conversion\n",
    "\n",
    "Convert multi-class labels (0-4) to binary classification:\n",
    "- **0** = Normal (No arrhythmia)\n",
    "- **1-4** = Abnormal (Any type of arrhythmia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48e004",
   "metadata": {},
   "source": [
    "## 2. Designing the 1D-CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817daef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels from training data\n",
    "X_train_full = train_data.iloc[:, :-1].values  # All columns except last\n",
    "y_train_full = train_data.iloc[:, -1].values   # Last column (labels)\n",
    "\n",
    "# Extract features and labels from test data\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "# Convert multi-class labels to binary: 0 = Normal, 1-4 = Abnormal â†’ 1\n",
    "y_train_binary = (y_train_full > 0).astype(int)\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "\n",
    "print(\"âœ“ Binary Label Conversion Complete\")\n",
    "print(f\"\\nLabel Distribution (Original Multi-class):\")\n",
    "print(f\"  Training: {np.unique(y_train_full, return_counts=True)}\")\n",
    "print(f\"  Test: {np.unique(y_test, return_counts=True)}\")\n",
    "\n",
    "print(f\"\\nLabel Distribution (Binary - 0=Normal, 1=Abnormal):\")\n",
    "unique_train, counts_train = np.unique(y_train_binary, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y_test_binary, return_counts=True)\n",
    "print(f\"  Training - Normal: {counts_train[0]}, Abnormal: {counts_train[1]}\")\n",
    "print(f\"  Test - Normal: {counts_test[0]}, Abnormal: {counts_test[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630c04c",
   "metadata": {},
   "source": [
    "## Section 5: Stratified Train-Validation Split\n",
    "\n",
    "Perform stratified 80-20 split on training data BEFORE any resampling to prevent data leakage.\n",
    "This maintains class distribution in both training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5260ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to (Samples, 187, 1) for 1D-CNN\n",
    "X_train_reshaped = X_train_full.reshape(-1, 187, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 187, 1)\n",
    "\n",
    "print(\"âœ“ Data Reshaping Complete for 1D-CNN\")\n",
    "print(f\"\\nOriginal shape: {X_train_full.shape}\")\n",
    "print(f\"Reshaped shape: {X_train_reshaped.shape}\")\n",
    "print(f\"\\nTest data reshaped: {X_test_reshaped.shape}\")\n",
    "print(f\"\\nData is ready for 1D-CNN architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e64ae9",
   "metadata": {},
   "source": [
    "## 4. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ CRITICAL: Perform stratified split BEFORE resampling to prevent data leakage\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_reshaped, \n",
    "    y_train_binary, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train_binary\n",
    ")\n",
    "\n",
    "print(\"âœ“ Stratified Train-Validation Split Complete (80-20)\")\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_reshaped.shape[0]} samples\")\n",
    "\n",
    "print(f\"\\nClass distribution preserved:\")\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "unique_val, counts_val = np.unique(y_val, return_counts=True)\n",
    "print(f\"  Training - Normal: {counts_train[0]}, Abnormal: {counts_train[1]}\")\n",
    "print(f\"  Validation - Normal: {counts_val[0]}, Abnormal: {counts_val[1]}\")\n",
    "print(f\"  Train ratio (Normal:Abnormal) = {counts_train[0]/counts_train[1]:.3f}\")\n",
    "print(f\"  Val ratio (Normal:Abnormal) = {counts_val[0]/counts_val[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863e075",
   "metadata": {},
   "source": [
    "## Section 6: Visualize Class Imbalance (Before SMOTE)\n",
    "\n",
    "Create a bar chart showing the class distribution of the training set BEFORE resampling.\n",
    "This demonstrates the severe imbalance in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bad05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class imbalance BEFORE SMOTE\n",
    "unique_before, counts_before = np.unique(y_train, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(['Normal (0)', 'Abnormal (1)'], counts_before, color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}\\n({height/len(y_train)*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Class Distribution BEFORE SMOTE (Training Set)\\nSevere Imbalance: ~90% Normal vs ~10% Abnormal', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, max(counts_before) * 1.15)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Class Imbalance Visualization Complete\")\n",
    "print(f\"\\nImbalance Ratio: {counts_before[0]/counts_before[1]:.2f}:1 (Normal:Abnormal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18552939",
   "metadata": {},
   "source": [
    "## Section 7: Apply SMOTE to Training Set Only\n",
    "\n",
    "Apply SMOTE (Synthetic Minority Over-sampling Technique) ONLY to the training set to achieve 1:1 class balance.\n",
    "This prevents data leakage and ensures validation/test sets remain unmodified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to training set only (NO RESAMPLING on validation/test)\n",
    "# Flatten data for SMOTE\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_smote_flat, y_train_smote = smote.fit_resample(X_train_flat, y_train)\n",
    "\n",
    "# Reshape back to 3D for CNN\n",
    "X_train_smote = X_train_smote_flat.reshape(-1, 187, 1)\n",
    "\n",
    "print(\"âœ“ SMOTE Applied to Training Set\")\n",
    "print(f\"\\nBefore SMOTE: {X_train.shape[0]} samples\")\n",
    "print(f\"After SMOTE: {X_train_smote.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution after SMOTE:\")\n",
    "unique_after, counts_after = np.unique(y_train_smote, return_counts=True)\n",
    "print(f\"  Normal (0): {counts_after[0]}\")\n",
    "print(f\"  Abnormal (1): {counts_after[1]}\")\n",
    "print(f\"  Ratio: 1:{counts_after[1]/counts_after[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7854b",
   "metadata": {},
   "source": [
    "## Section 8: Visualize Balanced Classes (After SMOTE)\n",
    "\n",
    "Create a bar chart showing the perfectly balanced class distribution after SMOTE application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize balanced classes AFTER SMOTE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Before SMOTE\n",
    "axes[0].bar(['Normal (0)', 'Abnormal (1)'], counts_before, color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=2)\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('BEFORE SMOTE\\nImbalanced Data', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "for i, (bar, count) in enumerate(zip(axes[0].patches, counts_before)):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., count,\n",
    "                f'{int(count)}\\n({count/len(y_train)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# After SMOTE\n",
    "axes[1].bar(['Normal (0)', 'Abnormal (1)'], counts_after, color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=2)\n",
    "axes[1].set_ylabel('Number of Samples', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('AFTER SMOTE\\nPerfectly Balanced (1:1 ratio)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "for i, (bar, count) in enumerate(zip(axes[1].patches, counts_after)):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., count,\n",
    "                f'{int(count)}\\n({count/len(y_train_smote)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ SMOTE Effectiveness Confirmed!\")\n",
    "print(f\"\\nImbalance Ratio Change:\")\n",
    "print(f\"  Before: {counts_before[0]/counts_before[1]:.2f}:1\")\n",
    "print(f\"  After: {counts_after[0]/counts_after[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b4211",
   "metadata": {},
   "source": [
    "## Section 9: Build 1D-CNN Architecture\n",
    "\n",
    "Construct a 1D-CNN model with:\n",
    "- 3 Conv1D layers (32 â†’ 64 â†’ 128 filters)\n",
    "- BatchNormalization after each convolution\n",
    "- MaxPooling1D for feature reduction\n",
    "- Dropout(0.3) for regularization\n",
    "- Dense output layer with sigmoid activation for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 1D-CNN model for ECG classification\n",
    "model = models.Sequential([\n",
    "    # First Conv Block\n",
    "    layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=(187, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Second Conv Block\n",
    "    layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Third Conv Block\n",
    "    layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Flatten and Dense\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Output layer for binary classification\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "print(\"\\nâœ“ 1D-CNN Model Architecture Created Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3dacee",
   "metadata": {},
   "source": [
    "## Section 10: Compile Model with Optimizer and Loss\n",
    "\n",
    "Compile the model using:\n",
    "- **Optimizer**: Adam (adaptive learning rate)\n",
    "- **Loss**: binary_crossentropy (for binary classification)\n",
    "- **Metrics**: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c79294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model Compiled Successfully\")\n",
    "print(f\"\\nOptimizer: Adam (lr=0.001)\")\n",
    "print(f\"Loss Function: binary_crossentropy\")\n",
    "print(f\"Metrics: accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5fdb0",
   "metadata": {},
   "source": [
    "## Section 11: Train Model with Early Stopping\n",
    "\n",
    "Train the model on SMOTE-balanced training data with:\n",
    "- Validation on the unseen validation set\n",
    "- EarlyStopping callback to prevent overfitting (patience=5)\n",
    "- 50 epochs with batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bdc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EarlyStopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model on SMOTE-balanced training data\n",
    "print(\"ðŸš€ Training the 1D-CNN model...\\n\")\n",
    "history = model.fit(\n",
    "    X_train_smote, y_train_smote,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Model Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c35e5c",
   "metadata": {},
   "source": [
    "## Section 12: Plot Training History (Accuracy & Loss)\n",
    "\n",
    "Visualize training and validation accuracy and loss over epochs to assess model learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, marker='o', markersize=4)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, marker='s', markersize=4)\n",
    "axes[0].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Model Accuracy vs Epochs', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "axes[1].set_xlabel('Epoch', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Model Loss vs Epochs', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Training history visualization complete\")\n",
    "print(f\"\\nFinal Training Results:\")\n",
    "print(f\"  Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"  Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Validation Loss: {history.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31ee8e",
   "metadata": {},
   "source": [
    "## Section 13: Evaluate on Test Set\n",
    "\n",
    "Evaluate the trained model on the purely unseen MIT-BIH test set (mitbih_test.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on unseen test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test_binary, verbose=0)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST SET EVALUATION (Unseen Data)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba3ac15",
   "metadata": {},
   "source": [
    "## Section 14: Generate Classification Report\n",
    "\n",
    "Generate a detailed classification report showing Precision, Recall, F1-Score for both Normal and Abnormal classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b338b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "y_test_pred_proba = model.predict(X_test_reshaped)\n",
    "y_test_pred = (y_test_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSIFICATION REPORT (Test Set)\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    y_test_binary, \n",
    "    y_test_pred,\n",
    "    target_names=['Normal (0)', 'Abnormal (1)'],\n",
    "    digits=4\n",
    "))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b99dc3",
   "metadata": {},
   "source": [
    "## Section 15: Plot Confusion Matrix Heatmap\n",
    "\n",
    "Visualize True Positives, True Negatives, False Positives, and False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, y_test_pred)\n",
    "\n",
    "# Plot confusion matrix as heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Normal (0)', 'Abnormal (1)'],\n",
    "            yticklabels=['Normal (0)', 'Abnormal (1)'],\n",
    "            annot_kws={'size': 14, 'weight': 'bold'})\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.title('Confusion Matrix - ECG Arrhythmia Detection (Test Set)', \n",
    "          fontsize=13, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix analysis\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFUSION MATRIX ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"True Negatives (Normal correctly identified):   {tn}\")\n",
    "print(f\"False Positives (Normal misclassified):         {fp}\")\n",
    "print(f\"False Negatives (Abnormal misclassified):       {fn}\")\n",
    "print(f\"True Positives (Abnormal correctly identified): {tp}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nSensitivity (Recall for Abnormal): {tp/(tp+fn):.4f}\")\n",
    "print(f\"Specificity (Recall for Normal):   {tn/(tn+fp):.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412395e4",
   "metadata": {},
   "source": [
    "## Section 16: Save Trained Model\n",
    "\n",
    "Save the final trained model to disk for future inference and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = 'ecg_model_final.h5'\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"âœ“ Model saved successfully!\")\n",
    "print(f\"  Location: {model_save_path}\")\n",
    "print(f\"  File size: {os.path.getsize(model_save_path) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Verify model can be loaded\n",
    "loaded_model = keras.models.load_model(model_save_path)\n",
    "print(f\"\\nâœ“ Model verification: Successfully loaded from disk\")\n",
    "print(f\"  Model can be used for inference!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING PIPELINE COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "âœ“ All steps completed successfully:\n",
    "  1. âœ“ Data loaded from MIT-BIH Arrhythmia Database\n",
    "  2. âœ“ Binary classification (Normal vs Abnormal)\n",
    "  3. âœ“ Data reshaped for 1D-CNN\n",
    "  4. âœ“ Stratified train-validation split (80-20)\n",
    "  5. âœ“ Class imbalance visualized\n",
    "  6. âœ“ SMOTE applied to training set only\n",
    "  7. âœ“ Balanced classes verified\n",
    "  8. âœ“ 1D-CNN architecture built\n",
    "  9. âœ“ Model compiled (Adam + binary_crossentropy)\n",
    "  10. âœ“ Model trained with EarlyStopping\n",
    "  11. âœ“ Training history plotted\n",
    "  12. âœ“ Evaluated on unseen test set\n",
    "  13. âœ“ Classification report generated\n",
    "  14. âœ“ Confusion matrix visualized\n",
    "  15. âœ“ Model saved as 'ecg_model_final.h5'\n",
    "  \n",
    "Final Test Accuracy: {test_accuracy*100:.2f}%\n",
    "Ready for deployment!\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
